use std::path::PathBuf;

use anyhow::anyhow;
use log::{error, info};
use sqlx::MySqlPool;

use buckets::public::media_files::bucket_file_path::MediaFileBucketPath;
use cloud_storage::remote_file_manager::remote_cloud_file_manager::RemoteCloudFileClient;
use errors::AnyhowResult;
use filesys::path_to_string::path_to_string;
use mysql_queries::queries::media_files::get::batch_get_media_files_by_tokens::{batch_get_media_files_by_tokens, MediaFilesByTokensRecord};
use mysql_queries::queries::media_files::get::get_media_file::{get_media_file, MediaFile};
use tokens::tokens::media_files::MediaFileToken;
use videos::ffprobe_get_dimensions::ffprobe_get_dimensions;

use crate::job::job_loop::process_single_job_error::ProcessSingleJobError;
use crate::job::job_types::workflow::comfy_ui::video_style_transfer::steps::check_and_validate_job::JobArgs;
use crate::job::job_types::workflow::comfy_ui::video_style_transfer::steps::secondary_video_and_paths::SecondaryVideoAndPaths;
use crate::job::job_types::workflow::comfy_ui::video_style_transfer::video_paths::VideoPaths;

pub struct VideoDownloadDetails {
  pub input_video_media_file: MediaFile,
  pub maybe_depth: Option<SecondaryVideoAndPaths>,
  pub maybe_normal: Option<SecondaryVideoAndPaths>,
  pub maybe_outline: Option<SecondaryVideoAndPaths>,
}

pub struct DownloadInputVideoArgs<'a> {
  pub job_args: &'a JobArgs<'a>,
  pub videos: &'a VideoPaths,
  pub mysql_pool: &'a MySqlPool,
  pub remote_cloud_file_client: &'a RemoteCloudFileClient,
}

pub async fn download_input_videos(
  args: DownloadInputVideoArgs<'_>
) -> Result<VideoDownloadDetails, ProcessSingleJobError> {
  let video_downloads = download_primary_video(&args).await?;
  let video_downloads = maybe_download_secondary_videos(video_downloads, &args).await?;
  Ok(video_downloads)
}

// TODO: Consolidate primary video download with secondary download logic.
async fn download_primary_video(
  args: &DownloadInputVideoArgs<'_>
) -> Result<VideoDownloadDetails, ProcessSingleJobError> {
  let input_media_file_token = match args.job_args.maybe_input_file {
    None => return Err(ProcessSingleJobError::InvalidJob(anyhow!("No primary input video file provided"))),
    Some(token) => token.clone(),
  };

  info!("Querying primary input media file by token: {:?} ...", &input_media_file_token);

  let mut input_media_file =  get_media_file(
    &input_media_file_token,
    false,
    args.mysql_pool
  ).await?.ok_or_else(|| {
    error!("primary input media_file not found: {:?}", &input_media_file_token);
    ProcessSingleJobError::Other(anyhow!("primary input media_file not found: {:?}", &input_media_file_token))
  })?;

  if let Some(source_media_file_token) = &input_media_file.maybe_style_transfer_source_media_file_token {
    // NB: We do this to avoid deep-frying the video.
    // This also lets us hide the engine renders from users.
    // This shouldn't ever become a deeply nested tree of children, but rather a single root
    // with potentially many direct children.
    // TODO(bt,2024-05-14): Perhaps fail open and use the first media file if the original
    //  isn't found?
    info!("Looking up original style transfer source media file...");
    input_media_file =  get_media_file(
      &source_media_file_token,
      true, // NB: In case the original was deleted, allow this to continue.
      args.mysql_pool
    ).await?.ok_or_else(|| {
      error!("source input media_file not found: {:?}", &input_media_file_token);
      ProcessSingleJobError::Other(anyhow!("source input media_file not found: {:?}",
        &input_media_file_token))
    })?;
  }

  let media_file_bucket_path = MediaFileBucketPath::from_object_hash(
    &input_media_file.public_bucket_directory_hash,
    input_media_file.maybe_public_bucket_prefix.as_deref(),
    input_media_file.maybe_public_bucket_extension.as_deref());

  info!("Primary input media file cloud bucket path: {:?}", media_file_bucket_path.get_full_object_path_str());

  info!("Downloading primary input file to {:?}", args.videos.original_video_path);

  args.remote_cloud_file_client.download_media_file(
    &media_file_bucket_path,
    path_to_string(&args.videos.original_video_path)
  ).await?;

  info!("Downloaded primary input video!");

  Ok(VideoDownloadDetails {
    input_video_media_file: input_media_file,
    maybe_depth: None,
    maybe_normal: None,
    maybe_outline: None,
  })
}

#[derive(Clone, Copy)]
enum SecondaryVideoType {
  Depth,
  Normal,
  Outline,
}

async fn maybe_download_secondary_videos(
  mut video_downloads: VideoDownloadDetails,
  args: &DownloadInputVideoArgs<'_>
) -> Result<VideoDownloadDetails, ProcessSingleJobError> {
  const CAN_SEE_DELETED : bool = true; // We don't need to care about the deleted flag.

  let mut tokens = Vec::with_capacity(3);

  if let Some(token) = args.job_args.maybe_depth_input_file {
    tokens.push(token.clone());
  }

  if let Some(token) = args.job_args.maybe_normal_input_file {
    tokens.push(token.clone());
  }

  if let Some(token) = args.job_args.maybe_outline_input_file {
    tokens.push(token.clone());
  }

  let results = batch_get_media_files_by_tokens(args.mysql_pool, &tokens, CAN_SEE_DELETED)
      .await
      .map_err(|err| {
        ProcessSingleJobError::Other(anyhow!("error querying secondary videos: {:?}", &err))
      })?;

  if let Some(token) = args.job_args.maybe_depth_input_file {
    video_downloads.maybe_depth =
        download_secondary_video(SecondaryVideoType::Depth, token, &results, args).await?;
  }

  if let Some(token) = args.job_args.maybe_normal_input_file {
    video_downloads.maybe_normal =
        download_secondary_video(SecondaryVideoType::Normal, token, &results, args).await?;
  }

  if let Some(token) = args.job_args.maybe_outline_input_file {
    video_downloads.maybe_outline =
        download_secondary_video(SecondaryVideoType::Outline, token, &results, args).await?;
  }

  Ok(video_downloads)
}

async fn download_secondary_video(
  secondary_video_type: SecondaryVideoType,
  desired_token: &MediaFileToken,
  all_video_media_files: &[MediaFilesByTokensRecord],
  args: &DownloadInputVideoArgs<'_>
) -> Result<Option<SecondaryVideoAndPaths>, ProcessSingleJobError> {

  let file_description = match secondary_video_type {
    SecondaryVideoType::Depth => "depth video",
    SecondaryVideoType::Normal => "normal video",
    SecondaryVideoType::Outline => "outline video",
  };

  let download_path = match secondary_video_type {
    SecondaryVideoType::Depth => args.videos.comfy_input_dir.join("depth_download.mp4"),
    SecondaryVideoType::Normal => args.videos.comfy_input_dir.join("normal_download.mp4"),
    SecondaryVideoType::Outline => args.videos.comfy_input_dir.join("outline_download.mp4"),
  };

  let maybe_media_file = all_video_media_files
      .iter()
      .find(|media_file| media_file.token.eq(desired_token));

  let media_file = match maybe_media_file {
    Some(media_file) => media_file,
    None => {
      error!("secondary input media_file '{}' not found: {:?}", file_description, desired_token);
      return Ok(None);
    }
  };

  let media_file_bucket_path = MediaFileBucketPath::from_object_hash(
    &media_file.public_bucket_directory_hash,
    media_file.maybe_public_bucket_prefix.as_deref(),
    media_file.maybe_public_bucket_extension.as_deref());

  info!("Media file '{}' cloud bucket path: {:?}",file_description,
    media_file_bucket_path.get_full_object_path_str());

  info!("Downloading '{}' media file to {:?}", file_description, download_path);

  args.remote_cloud_file_client.download_media_file(
    &media_file_bucket_path,
    path_to_string(&download_path)
  ).await?;

  Ok(Some(SecondaryVideoAndPaths {
    media_file: media_file.clone(),
    original_download_path: download_path,
    maybe_processed_path: None,
  }))
}
