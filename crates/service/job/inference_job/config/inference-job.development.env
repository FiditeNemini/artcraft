# inference-job default .env configurations (these can be overridden with k8s)

# NB: For my crapy internet connection
BUCKET_TIMEOUT_SECONDS=6000

# NB: To not step on storyteller-web (the main API gateway)
HTTP_BIND_ADDRESS=0.0.0.0:11223

# NB: Disable if not testing Redis
REDIS_FOR_KEEPALIVE_URL="redis://localhost/0"

# ================================= #
#                                   #
#            Vall-E-X               #
#                                   #
# ================================= #

# should rename my folder 
# abs path to the folder that contains the inference code need to get that container in the repo need basepath? relative to everyones env
VALL_E_X_INFERENCE_ROOT_DIRECTORY = "/home/tensor/code/storyteller/storyteller-ml/tts/VALL-E-X" 
VALL_E_X_INFERENCE_COMMAND = "python3 main.py"
VALL_E_X_INFERENCE_MAYBE_VENV_COMMAND = "source .env/bin/activate"
# VALL_E_X_INFERENCE_MAYBE_DOCKER_IMAGE = "" # fill this out for dev?

# ================================= #
#                                   #
#             RVC (v2)              #
#                                   #
# ================================= #

RVC_V2_INFERENCE_ROOT_DIRECTORY="/home/bt/dev/storyteller/storyteller-ml/voice_conversion/rvc-v2-brandon"
RVC_V2_INFERENCE_COMMAND="python fakeyou_infer.py"
RVC_V2_INFERENCE_MAYBE_VENV_COMMAND="source python/bin/activate"

# ================================= #
#                                   #
#            SAD TALKER             #
#                                   #
# ================================= #

SAD_TALKER_INFERENCE_ROOT_DIRECTORY="/home/bt/dev/storyteller/storyteller-ml/animation/SadTalker"
SAD_TALKER_INFERENCE_COMMAND="python inference.py"
SAD_TALKER_INFERENCE_MAYBE_VENV_COMMAND="source python/bin/activate"

# ================================= #
#                                   #
#          FFMPEG WATERMARK         #
#                                   #
# ================================= #

FFMPEG_LOGO_LOGO_PATH="/home/bt/dev/storyteller/storyteller-rust/includes/container_includes/image_assets/fakeyou_watermark.png"

# ================================= #
#                                   #
#           SO-VITS-SVC             #
#                                   #
# ================================= #

# Cache hubert in a recoverable place so do don't constantly re-download it.
HUBERT_PATH="/tmp/hubert/checkpoint_best_legacy_500.pt"

SO_VITS_SVC_INFERENCE_ROOT_DIRECTORY="/models/voice_conversion/so-vits-svc/src" #NB: so-vits-svc-paul-2
SO_VITS_SVC_INFERENCE_MAYBE_DOCKER_IMAGE="247952d65c82" # so-vits-svc-paul-2: --f0-method
SO_VITS_SVC_INFERENCE_COMMAND="/install/python/bin/python3.10 fakeyou_infer.py" # NB: so-vits-svc-paul-2
SO_VITS_SVC_INFERENCE_MAYBE_DEFAULT_CONFIG_PATH="/models/voice_conversion/so-vits-svc/example_config.json"
#SO_VITS_SVC_INFERENCE_MAYBE_VENV_COMMAND="source python/bin/activate"

# ================================= #
#                                   #
#         TACOTRON (LEGACY)         #
#                                   #
# ================================= #

## Old docker image
#TACOTRON2_VOCODES_DOCKER_IMAGE_SHA=1ba08f70f2ba

TT2_LEGACY_ROOT_DIRECTORY="/models/tts"
TT2_LEGACY_MAYBE_PYTHON_INTERPRETER="python3.6"
TT2_LEGACY_MAYBE_DOCKER_IMAGE_SHA="9f1945388110"

# ================================= #
#                                   #
#              VITS                 #
#                                   #
# ================================= #

VITS_INFERENCE_ROOT_DIRECTORY="/vits"
VITS_INFERENCE_SCRIPT="infer_ts_job.py"
VITS_INFERENCE_MAYBE_PYTHON_INTERPRETER="python3"
VITS_INFERENCE_MAYBE_DOCKER_IMAGE_SHA="03017896367b"

# ================================= #
#                                   #
#          CACHE SETTINGS           #
#                                   #
# ================================= #

# Huggingface caches data at ~/.cache/huggingface (/root/cache/huggingface),
# which isn't the shared volume and will get blown away.
# HF_HOME="/tmp/huggingface"
HF_DATASETS_CACHE="/tmp/huggingface"

# nltk also caches data.
NLTK_DATA="/tmp/nltk_data"
