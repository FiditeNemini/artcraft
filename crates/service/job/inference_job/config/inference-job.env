# inference-job default .env configurations (these can be overridden with k8s)

# NB: For my crapy internet connection
BUCKET_TIMEOUT_SECONDS=600

SO_VITS_SVC_INFERENCE_ROOT_DIRECTORY="/models/voice_conversion/so-vits-svc"
#SO_VITS_SVC_INFERENCE_MAYBE_VENV_COMMAND="source python/bin/activate"
SO_VITS_SVC_INFERENCE_MAYBE_DOCKER_IMAGE="8acacf30bb2e"

TT2_LEGACY_ROOT_DIRECTORY="/models/tts"
TT2_LEGACY_MAYBE_PYTHON_INTERPRETER="python3.6"
TT2_LEGACY_MAYBE_DOCKER_IMAGE_SHA="9f1945388110"

VITS_INFERENCE_ROOT_DIRECTORY="/vits"
VITS_INFERENCE_SCRIPT="infer_ts_job.py"
VITS_INFERENCE_MAYBE_PYTHON_INTERPRETER="python3"
VITS_INFERENCE_MAYBE_DOCKER_IMAGE_SHA="03017896367b"

# Huggingface caches data at ~/.cache/huggingface (/root/cache/huggingface),
# which isn't the shared volume and will get blown away.
# HF_HOME="/tmp/huggingface"
HF_DATASETS_CACHE="/tmp/huggingface"

# nltk also caches data.
NLTK_DATA="/tmp/nltk_data"
