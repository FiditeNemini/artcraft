# inference-job default .env configurations (these can be overridden with k8s)

TT2_LEGACY_ROOT_DIRECTORY="/models/tts"
TT2_LEGACY_MAYBE_DOCKER_IMAGE_SHA="4e75028a075f"

VITS_INFERENCE_ROOT_DIRECTORY="/vits"
VITS_INFERENCE_SCRIPT="infer_ts_job.py"
VITS_INFERENCE_MAYBE_PYTHON_INTERPRETER="python3"
VITS_INFERENCE_MAYBE_DOCKER_IMAGE_SHA="03017896367b"

# Huggingface caches data at ~/.cache/huggingface (/root/cache/huggingface),
# which isn't the shared volume and will get blown away.
# HF_HOME="/tmp/huggingface"
HF_DATASETS_CACHE="/tmp/huggingface"

# nltk also caches data.
NLTK_DATA="/tmp/nltk_data"
