use buckets::util::hashed_directory_path_short_string::hashed_directory_path_short_string;
use container_common::anyhow_result::AnyhowResult;
use std::path::PathBuf;

/// This is designed to make it centrally configurable where
/// different types of objects are stored.
#[deprecated(note = "see the 'buckets' crate for a better approach")]
pub struct BucketPathUnifier {
  // TTS
  pub tts_synthesizer_model_root: PathBuf,
  pub tts_inference_output_root: PathBuf,
  pub tts_pretrained_vocoder_model_root: PathBuf, // Pretrained, non-user uploaded vocoders
  pub vocoder_model_root: PathBuf, // User-uploaded vocoders
  // W2L
  pub user_uploaded_w2l_templates_root: PathBuf,
  pub user_uploaded_audio_for_w2l_root: PathBuf,
  pub w2l_inference_output_root: PathBuf,
  pub w2l_model_root: PathBuf,
  pub w2l_end_bump_root: PathBuf,
  // VC
  pub softvc_model_root: PathBuf,
}

impl BucketPathUnifier {

  pub fn default_paths() -> Self {
    Self {
      // TTS
      tts_synthesizer_model_root: PathBuf::from("/user_uploaded_tts_synthesizers"),
      tts_inference_output_root: PathBuf::from("/tts_inference_output"),
      tts_pretrained_vocoder_model_root: PathBuf::from("/tts_pretrained_vocoders"), // Pretrained, non-user uploaded vocoders
      vocoder_model_root: PathBuf::from("/user_uploaded_vocoders"),
      // W2L
      user_uploaded_audio_for_w2l_root: PathBuf::from("/user_uploaded_w2l_audio"),
      user_uploaded_w2l_templates_root: PathBuf::from("/user_uploaded_w2l_templates"),
      w2l_inference_output_root: PathBuf::from("/w2l_inference_output"),
      w2l_model_root: PathBuf::from("/w2l_pretrained_models"),
      w2l_end_bump_root: PathBuf::from("/w2l_end_bumps"),
      // VC
      softvc_model_root: PathBuf::from("/user_uploaded_softvc_models"),
    }
  }

  // ==================== TTS MODELS (SYNTHESIZER + VOCODER) ==================== //

  // NB: Callers use "hash_file_sha2" as the file hash.
  pub fn tts_synthesizer_path(&self, tts_synthesizer_file_hash: &str) -> PathBuf {
    let hashed_path = Self::hashed_directory_path(tts_synthesizer_file_hash);
    let model_filename = format!("{}.pt", &tts_synthesizer_file_hash);

    self.tts_synthesizer_model_root
      .join(hashed_path)
      .join(model_filename)
  }

  pub fn tts_zipped_synthesizer_path(&self, tts_synthesizer_file_hash: &str) -> PathBuf {
    let hashed_path = Self::hashed_directory_path(tts_synthesizer_file_hash);
    let model_filename = format!("{}.zip", &tts_synthesizer_file_hash);

    self.tts_synthesizer_model_root
        .join(hashed_path)
        .join(model_filename)
  }

  // ==================== VOCODER MODELS ==================== //

  /// TTS pretrained vocoder models.
  /// For now this will be limited, but once they're user-uploadable, we'll add more.
  /// NB: These are vocoders that we uploaded without the FakeYou upload system!!
  pub fn tts_pretrained_vocoders_path(&self, tts_vocoder_model_name: &str) -> PathBuf {
    self.tts_pretrained_vocoder_model_root.join(tts_vocoder_model_name)
  }

  // NB: Callers use "hash_file_sha2" as the file hash.
  /// User-uploaded vocoders.
  /// These can be HifiGan and HifiGanSoftVc
  pub fn vocoder_path(&self, vocoder_file_hash: &str) -> PathBuf {
    let hashed_path = Self::hashed_directory_path(vocoder_file_hash);
    let model_filename = format!("{}.pt", &vocoder_file_hash);

    self.vocoder_model_root
        .join(hashed_path)
        .join(model_filename)
  }

  // ==================== TTS INFERENCE OUTPUT ==================== //

  // NB: Callers use job uuid_idempotency_token, which seems *bad*
  /// This should include the string "vocodes" for downloaders.
  pub fn tts_inference_wav_audio_output_path(&self, tts_inference_output_uuid: &str) -> PathBuf {
    let hashed_path = Self::hashed_directory_path(tts_inference_output_uuid);
    let audio_filename = format!("vocodes_{}.wav", &tts_inference_output_uuid);

    self.tts_inference_output_root
        .join(hashed_path)
        .join(audio_filename)
  }

  pub fn tts_inference_spectrogram_output_path(&self, tts_inference_output_uuid: &str) -> PathBuf {
    let hashed_path = Self::hashed_directory_path(tts_inference_output_uuid);
    let json_filename = format!("{}.json", &tts_inference_output_uuid);

    self.tts_inference_output_root
        .join(hashed_path)
        .join(json_filename)
  }

  // ==================== W2L STATIC RESOURCES ==================== //

  // W2L pretrained models. There are only two.
  pub fn w2l_pretrained_models_path(&self, w2l_model_name: &str) -> PathBuf {
    self.w2l_model_root.join(w2l_model_name)
  }

  // W2L "end bumps" are videos added at the end.
  pub fn end_bump_video_for_w2l_path(&self, end_bump_filename: &str) -> PathBuf {
    self.w2l_end_bump_root.join(end_bump_filename)
  }

  // ==================== W2L USER-UPLOADED RESOURCES ==================== //

  // The video or images uploaded as templates
  // eg. /user_uploaded_w2l_templates/1/5/1/151a[...60]...
  pub fn media_templates_for_w2l_path(&self, template_file_hash: &str) -> PathBuf {
    let hashed_path = Self::hashed_directory_path(template_file_hash);
    self.user_uploaded_w2l_templates_root
      .join(hashed_path)
      .join(template_file_hash)
  }

  // These share the same directory as the uploaded w2l template media.
  // eg. /user_uploaded_w2l_templates/1/5/1/151a[...60]_detected_faces.pickle
  pub fn precomputed_faces_for_w2l_path(&self, template_file_hash: &str) -> PathBuf {
    let faces_filename = format!("{}_detected_faces.pickle", &template_file_hash);
    let hashed_path = Self::hashed_directory_path(template_file_hash);

    self.user_uploaded_w2l_templates_root
      .join(hashed_path)
      .join(faces_filename)
  }

  // User-uploaded audio.
  // eg. /user_uploaded_w2l_audio/0/0/b/00bcc7a4-bdf5-43a5-9603-a15ca780d866
  pub fn user_audio_for_w2l_inference_path(&self, audio_uuid: &str) -> PathBuf {
    let hashed_path = Self::hashed_directory_path(audio_uuid);
    self.user_uploaded_audio_for_w2l_root
      .join(hashed_path)
      .join(audio_uuid)
  }

  // ==================== W2L INFERENCE OUTPUT ==================== //

  // NB: caller uses inference job token, which seems ideal
  // W2L inference output videos
  pub fn w2l_inference_video_output_path(&self, w2l_inference_job_token: &str) -> PathBuf {
    // NB: We don't want colons from the token in the filename.
    if w2l_inference_job_token.contains(":") {
      if let Some((token_type, token)) = w2l_inference_job_token.split_once(":") {
        let video_filename = w2l_inference_job_token.replace(":", "");
        let video_filename = format!("vocodes_video_{}.mp4", video_filename);

        let hashed_path = Self::hashed_directory_path(token);
        let hashed_path = hashed_path.to_lowercase();

        return self.w2l_inference_output_root
          .join(hashed_path)
          .join(video_filename);
      }
    }

    let video_filename = w2l_inference_job_token.replace(":", "");
    let video_filename = format!("vocodes_video_{}.mp4", video_filename);

    let hashed_path = Self::hashed_directory_path(w2l_inference_job_token);

    self.w2l_inference_output_root
      .join(hashed_path)
      .join(video_filename)
  }

  // ==================== VOICE CONVERSION MODELS ==================== //

  // NB: Callers use "hash_file_sha2" as the file hash.
  pub fn softvc_model_path(&self, softvc_model_file_hash: &str) -> PathBuf {
    let hashed_path = Self::hashed_directory_path(softvc_model_file_hash);
    let model_filename = format!("{}.pt", &softvc_model_file_hash);

    self.softvc_model_root
        .join(hashed_path)
        .join(model_filename)
  }

  // ==================== UTILITY ==================== //

  pub fn hashed_directory_path(file_hash: &str) -> String {
    hashed_directory_path_short_string(file_hash)
  }
}

#[cfg(test)]
mod tests {
  use crate::bucket_path_unifier::BucketPathUnifier;
  use std::path::PathBuf;

  fn get_instance() -> BucketPathUnifier {
    BucketPathUnifier {
      // TTS
      tts_synthesizer_model_root: PathBuf::from("/test_path_synthesizers"),
      tts_inference_output_root: PathBuf::from("/test_path_tts_output"),
      tts_pretrained_vocoder_model_root: PathBuf::from("/test_path_tts_vocoders"), // Pretrained, non-user uploaded vocoders
      vocoder_model_root: PathBuf::from("/test_path_user_vocoders"), // User-uploaded vocoders
      // W2L
      user_uploaded_w2l_templates_root: PathBuf::from("/test_path_w2l_templates"),
      user_uploaded_audio_for_w2l_root: PathBuf::from("/test_path_w2l_audio"),
      w2l_inference_output_root: PathBuf::from("/test_path_w2l_output"),
      w2l_model_root: PathBuf::from("/test_path_w2l_pretrained_models"),
      w2l_end_bump_root: PathBuf::from("/test_path_w2l_end_bumps"),
      // VOICE CONVERSION
      softvc_model_root: PathBuf::from("/test_path_softvc_models"),
    }
  }

  // NB: Pretrained, non-user uploaded vocoders
  #[test]
  fn test_tts_pretrained_vocoders_path() {
    let paths = get_instance();
    assert_eq!(paths.tts_pretrained_vocoders_path("melgan.pth").to_str().unwrap(),
      "/test_path_tts_vocoders/melgan.pth");
  }

  // NB: User-uploaded vocoders
  #[test]
  fn test_vocoders_path() {
    let paths = get_instance();
    assert_eq!(paths.vocoder_path("foobar").to_str().unwrap(),
      "/test_path_user_vocoders/f/o/o/foobar.pt");
  }

  #[test]
  fn test_tts_synthesizer_path() {
    let paths = get_instance();
    assert_eq!(paths.tts_synthesizer_path("foobar").to_str().unwrap(),
      "/test_path_synthesizers/f/o/o/foobar.pt");
  }

  #[test]
  fn test_tts_zipped_synthesizer_path() {
    let paths = get_instance();
    assert_eq!(paths.tts_zipped_synthesizer_path("foobar").to_str().unwrap(),
      "/test_path_synthesizers/f/o/o/foobar.zip");
  }

  #[test]
  fn test_tts_inference_wav_audio_output_path() {
    let paths = get_instance();
    assert_eq!(paths.tts_inference_wav_audio_output_path("foobar").to_str().unwrap(),
      "/test_path_tts_output/f/o/o/vocodes_foobar.wav");
  }

  #[test]
  fn test_tts_inference_spectrogram_output_path() {
    let paths = get_instance();
    assert_eq!(paths.tts_inference_spectrogram_output_path("foobar").to_str().unwrap(),
      "/test_path_tts_output/f/o/o/foobar.json");
  }

  #[test]
  fn test_w2l_pretrained_models_path() {
    let paths = get_instance();
    assert_eq!(paths.w2l_pretrained_models_path("model.pth").to_str().unwrap(),
               "/test_path_w2l_pretrained_models/model.pth");
  }

  #[test]
  fn test_end_bump_video_for_w2l_path() {
    let paths = get_instance();
    assert_eq!(paths.end_bump_video_for_w2l_path("logo.mp4").to_str().unwrap(),
               "/test_path_w2l_end_bumps/logo.mp4");
  }

  #[test]
  fn test_user_audio_for_w2l_inference_path() {
    let paths = get_instance();
    assert_eq!(paths.user_audio_for_w2l_inference_path("foobar").to_str().unwrap(),
               "/test_path_w2l_audio/f/o/o/foobar");
  }

  #[test]
  fn test_media_templates_for_w2l_path() {
    let paths = get_instance();
    assert_eq!(paths.media_templates_for_w2l_path("foobar").to_str().unwrap(),
               "/test_path_w2l_templates/f/o/o/foobar");
  }

  #[test]
  fn test_precomputed_faces_for_w2l_path() {
    let paths = get_instance();
    assert_eq!(paths.precomputed_faces_for_w2l_path("foobar").to_str().unwrap(),
               "/test_path_w2l_templates/f/o/o/foobar_detected_faces.pickle");
  }

  #[test]
  fn test_w2l_inference_video_output_path() {
    let paths = get_instance();

    // Case 1: Tokens without a "token type"
    assert_eq!(paths.w2l_inference_video_output_path("foobar").to_str().unwrap(),
               "/test_path_w2l_output/f/o/o/vocodes_video_foobar.mp4");

    // Case 2: Tokens with a "token type"
    // Note: that it removes the token type from dir path and handles the colon:
    assert_eq!(paths.w2l_inference_video_output_path("type:abcdef").to_str().unwrap(),
               "/test_path_w2l_output/a/b/c/vocodes_video_typeabcdef.mp4");

    // It also handles capitalization
    assert_eq!(paths.w2l_inference_video_output_path("TYPE:ABCDEF").to_str().unwrap(),
               "/test_path_w2l_output/a/b/c/vocodes_video_TYPEABCDEF.mp4");
  }

  #[test]
  fn test_softvc_model_path() {
    let paths = get_instance();
    assert_eq!(paths.softvc_model_path("foobar").to_str().unwrap(),
               "/test_path_softvc_models/f/o/o/foobar.pt");
  }

  #[test]
  fn hashed_directory_path_length_zero() {
    assert_eq!(&BucketPathUnifier::hashed_directory_path(""), "");
  }

  #[test]
  fn hashed_directory_path_length_one() {
    assert_eq!(&BucketPathUnifier::hashed_directory_path("a"), "");
  }

  #[test]
  fn hashed_directory_path_length_two() {
    assert_eq!(&BucketPathUnifier::hashed_directory_path("ab"), "a/");
  }

  #[test]
  fn hashed_directory_path_length_three() {
    assert_eq!(&BucketPathUnifier::hashed_directory_path("abc"), "a/b/");
  }

  #[test]
  fn hashed_directory_path_length_more() {
    assert_eq!(&BucketPathUnifier::hashed_directory_path("abcd"), "a/b/c/");
    assert_eq!(&BucketPathUnifier::hashed_directory_path("abcde"), "a/b/c/");
    assert_eq!(&BucketPathUnifier::hashed_directory_path("abcdef01234"), "a/b/c/");
  }
}
