[
  {
    "slug": "world-models-for-film",
    "title": "Machinima 2.0: World Models for Consistent AI Filmmaking",
    "description": "How to use World Models and 3D Rendering to Get Consistent AI Film Locations and better AI Films.",
    "date": "2026-01-30",
    "body": "\n# The \"AI Film Trailer\" Era\n\nYou've seen a lot of these: \n\n@youtube(pGn-1BKo3nY)\n\nFor the past year, it been relatively easy to make montages, \"clip shows\", and trailers\nlike this. While they serve as fun proof-of-concepts and visual eyecandy, you'd be hard \npressed to get a \"good story\" out of this video style.\n\nGood stories have characters that occupy real spaces. They have room to live, breathe, and interact. \n\nYou don't just fast track everyone through a journey from point A to B and have that be the end of things \n(unless you're Game of Thrones). Characters need to spend time in places, to explore interpersonal relationships, \nto overcome challenges. They need places to think, talk, fight and argue, process emotions, grow, and sometimes \ndo absolutely nothing at all.\n\nStories need locations. They're a first class citizen in storytelling.\n\n# Location and Blocking\n\nWe're all filmmakers at ArtCraft. The old school, photons-on-glass kind.\n\nOne of the biggest problems we've had over the past few years with AI video is giving our characters room to occupy. \nSetting them up on set, precisely controlling what's on screen, and maintaining consistency with their location. \nThe majority of AI video right now looks like a series of disconnected clips, which results in \nAI film having that \"film trailer\" montage feel to it. Lots of jumping around, very little \ncontinuity.\n\nWe've figured out how to overcome this problem. And in the spirit of \"Show, Don't Tell\", \nlet me show you what we've discovered. You'll intuit how this technique works immediately:\n\n@youtube(kzvQMdg66Go)\n\nNow let me break down the rationale and the technique...\n\n# Moving the Camera is Important\n\nIn *\"film language\"*, the camera's relationship to the characters conveys meaning. Sometimes we want to give the \nviewer a warm and friendly perspective, or perhaps frame the relationship between two different characters and \nimply a certain power dynamic.\n\nSometimes it's just important to show the location so the viewer can settle in. So the setting feels lived in and \nthe viewer is immersed in it alongside our characters.\n\n# Text is a Coarse-Grained Representation\n\nHere's a simple Nano Banana Pro prompt:\n\n> Sam Altman in a room. He sits at a desk, looking towards a desktop computer on the left. \n> The room is dimly lit. The glow of a computer terminal, sitting in front of him bathes the room in blue light. \n> Behind him, there is a wall with a poster. There’s an AC/DC poster on the left, and a window on the right. \n> Through the window, there’s a view of moonlit trees. \n\nAnd the results: \n\n![Hi Sam!](./images/blog/sam4.png)\n\nWhat happened to the location here? Why are none of these the same? Why are the locations of the poster, \ncomputer, window, and so forth so imprecise? \n\nMoreover, how do we adjust this? Iteratively prompting?\n\nYou already know the answer: text is a poor serialization of the physical world. Text-to-Image is coarse \ngrained. It lacks the ability to precisely convey physical attributes and spatial relationships. You can try, \nbut you'll only get so much precision, and it'll never match the vision in your head.\n\n# Images are Incomplete\n\nThere are multiple ways to move a camera in an image-to-image workflow. You can use a ControlNet, a LoRA, or even \nask an instructive model nicely:\n\n> Rotate the camera behind Sam Altman to show him from behind. Show the desk, computer screen, \n> and wall behind the desk. Show the door to the room. \n\n![Hi Sam!](./images/blog/sam4.2.png)\n\nWhile the lighting and scene elements remain somewhat consistent, we're still ultimately left with the same \nissues we had with text-to-image. We can iterate on editing with words, but it's slow, tedious, and still \nimprecise.\n\n(Why does the desk block the door? What is it even trying to do with that poster?)\n\n# 3D to the Rescue!\n\nOne of the best tools for consistency is 3D. You can position your characters and props in a \"3D set\" exactly as you want them, \nand then move the \"camera\" to any angle, maintaining strong consistency throughout.\n\n![Hi Sam!](./images/blog/sam_previz.png)\n\nPick a \"smart\" model like GPT Image 1.5 or Nano Banana Pro to convert this previz into a photorealistic render (or any style - anime, sci-fi, whatever): \n\n> Suspense movie - live action - night time. Make a photorealistic picture of Sam Altman sitting at a fancy office desk. \n> Use the previz scene as the layout and posing of the shot. The camera and pose of Sam should match this shot. \n> Nighttime shot, moonlit glow. \n\n![Hi Sam!](./images/blog/sam_gpt_image_1.png)\n\nIf desired, you can also attach additional reference images for character designs, wardrobe choices, etc.\n\nAfter Nano Banana Pro lighting adjustments and upscaling (and showing it the previz again to restore the missing desk pad), we get this:\n\n> Make this look more photorealistic. Suspenseful night in the office\n\n![Hi Sam!](./images/blog/sam_nbp2.png)\n\nIt's a great starting composition before calling \"action\" with a video model. (I'm no Roger Deakins. I would adjust the framing, but I wanted to show under the desk as well as bookcase features. I was also up late writing this.)\n\n# 3D Kit Bashing \n\nYou can use 3D kits found online, many of which are free or low cost, to \"kit bash\" a scene. Synty, CGTrader, ... there are hundreds of sites for locations, objects, characters, and more. With these assets, you can provide exact blocking and layout you want - but more importantly, you can reuse them for additional shots and camera angles. Your characters need to be seen from multiple angles, and your props need to be consistent throughout the scene.\n\n> Action movie - live action - day. Turn this previz scene into a photorealistic desert island. Keep the tree, boxes, and treasure chest in place. \n\n![Island](./images/blog/island_previz.png)\n\nAnd the render, with one extra NBP 4K upscale (I did ask it to change the clouds on the second pass): \n\n![Island](./images/blog/island_nbp.png)\n\nImage editing models are also surprisingly robust at changing the composition controllably if you give it enough structure to start with.\n\n# Greyboxing\n\nBut kit bashing can be slow. You have to find and curate a selection of assets. \nIf you need to go faster, you can use 3D primitive shapes to \"greybox\" a scene:\n\n![Greyboxing](./images/blog/ruins_previz.png)\n\n> Historical epic - live action - sunset. Use this previz scene for the composition. \n> An ancient greek temple with ruined concrete and marble columns. The pink and orange sunset bathes the concrete and marble. \n> In the distance, there are rolling green hills and valleys. Bright pink sky. \n\n![Greyboxing](./images/blog/ruins_nbp.png)\n\nYou can drop 3D assets in alongside the greybox to position existing props or characters. You can even greybox just a single element, like a TV.\n\n# Billboards and Matte Plates\n\nIf you want to add a dramatic backdrop behind characters and a foreground, you can use the old Hollywood technique of creating a background plate (think the \"matte paintings\" used in Star Wars). In video game parlance, this is called using flat or billboard textures. \n\nIt's quick and easy, though you do lose your ability to rotate the camera. Use it for depth and backdrops:\n\n![Billboards](./images/blog/snow_previz.png)\n\n> Sports footage - live action - day. Woman is hiking in the mountains. She is dressed in sporty warm winter wear. \n> She’s standing at the peak, with a mountain forest behind her. Use this previz image to upscale the photo into a \n> fully lifelike and photorealistic cinematic image.\n\n![Billboards](./images/blog/snow_nbp.png)\n\n\n# Object Generation for Props\n\nYou can turn images into 3D prop objects using models such as Hunyuan 3D. This is useful if you need angles and \nprecision posing for a complicated object, or if you intend to use the asset over and over and need consistency.\n\nI generated a quick photo of an FJ Cruiser SUV:\n\n![Object Generation](./images/blog/fj_gen.png)\n\nTurning this into a 3D object and instancing it around all over the place:\n\n![Object Generation](./images/blog/fj_previz.png)\n\nThen prompt, followed by a 4K upscale (with a few more fixes):\n\n> An artistic collage of fj cruiser SUVs floating in a pixelated desert. \n> Match their pose and orientations exactly, including the ones that are flipped and rotated. \n> Make the low poly fj cruisers look photorealistic and high resolution.\n\n![Object Generation](./images/blog/fj_nbp.png)\n\n\n# World Models Make This Easy\n\nThe real stars of the modern 3D compositing workflow are image-to-Gaussian Splat models, such as World Labs' Marble or Apple's Sharp. \n\nYou can very quickly create a pleasing image of an intracate set in MidJourney, edit it in Nano Banana, \nthen turn it into a fully navigable 3D scene. This gives your characters room to move, your camera places \nto go, and your location opportunities to shine. \n\n@loop_autoplay(https://pub-f7441936e5804042a1ea2bdc92e4dc71.r2.dev/Fantasy_Gif_One.mp4)\n@loop_autoplay(https://pub-f7441936e5804042a1ea2bdc92e4dc71.r2.dev/Beach_Gif_One.mp4)\n@loop_autoplay(https://pub-f7441936e5804042a1ea2bdc92e4dc71.r2.dev/SciFi_Gif_One.mp4)\n\nFinally, we have set pieces. And they're easy to build and iterate on.\n\n# Combining Techniques\n\nYou can use MidJourney to quickly generate brilliant scenes with high detail and magazine photoshoot quality layout, or you can draw a sketch or greybox a scene you'd like to build, iterate, then turn that into a world. \n\nThis is less like \"prompting\" and more like \"crafting\", with lots of different visual tools used in quick succession and coordination. \n\nNeed something? Generate it, turn it into 3D, edit, manipulate it. Stick it into something else. Rinse, cycle, repeat. Highly tangible, \nlike an artist molding clay - except now we're moving closer to the speed of thoughts. \n\nWe're still being largely intentional. If there's something we want to see, we now have the tool to make it real. It's *What You See Is What You Get*. \n\nWe're painting with pictures. We're not prompters, but rather auteurs of crafting.\n\n# Machinima 2.0\n\nDo you remember \"Machinima\"? It's a niche, indie genre of filmmaking that was popular in the early 2000's. Creators would pilot video game characters, carefully controlling for the camera, character movements, and on-screen details in order to tell stories. They would then dub over the footage to breathe life into the narrative. \n\nPopular Machinima series include \"Red vs. Blue\", from Rooster Teeth Productions, which was filmed using the Halo video game series. Other notable Machinima include \"The Strangerhood\" (which used The Sims) and \"Skibidi Toilet\" (which leverages Source Filmmaker). \n\nI mention this obsucre artform because as a former Machinima creator myself, it feels like Image-to-Video is the new Machinima. There's the character posting, keyframing, and dubbing, of course, but there's also this notion of using pixels created by someone else's engine. And it's very much in the spirit of machinima to carve new creativity out of these engines by operating at a higher level. \n\nImage-to-image, 3D, and World Models make an entirely new form of Machinima possible:\n\n@youtube(tAAiiKteM-U)\n\n\n# ArtCraft: Free and Open 3D Filmmaking\n\nArtCraft is a crafting engine and is available in its entirety on [Github (please star us!)](https://github.com/storytold/artcraft), or try it today on [Mac or Windows](/download).\n\nYou generate images and videos in app using a wide selection of models and providers\nsuch as Midjourney, Google, Sora, Grok, WorldLabs, and more - or you can bring your own keys!\n\nOver the coming weeks, we'll be adding FAL, Replicate, and Google Gemini. Local GPU support and RunPod support \nis also coming soon (subscribe to stay updated, or better yet, [join our Discord](https://discord.gg/artcraft)).\n\nIf you're a blogger, podcaster, or creator we've got a [ton of CC-BY-SA content here](/press-kit#top) if you'd like to help us let people know about ArtCraft.\n\nIf you're a creative, please enjoy ArtCraft. We built it for ourselves and for you. Please join the community and let us know if there's any way we can help. \n\n&mdash; Brandon Thomas\n\n"
  },
  {
    "slug": "welcome",
    "title": "Welcome to the ArtCraft Blog",
    "description": "We are excited to launch our new blog where we will share updates, tutorials, and behind-the-scenes content.",
    "date": "2026-01-16",
    "body": "\n# Hello World!\n\nWelcome to the official **ArtCraft Blog**. This is where we'll be posting about:\n\n- **New Features**: Be the first to know about the latest tools and capabilities added to ArtCraft.\n- **Tutorials**: Learn how to get the most out of our AI generation and editing suite.\n- **Community Showcases**: Highlighting amazing work created by our users.\n- **Development Updates**: Insights into what we are building next.\n\n## Stay Tuned\n\nWe have a lot of exciting things in the pipeline. Make sure to check back regularly!\n\nHappy Crafting!\n\nThe ArtCraft Team\n"
  }
]