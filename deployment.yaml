---
kind: Service
apiVersion: v1
metadata:
  name: tts
  namespace: mumble
spec:
  type: LoadBalancer
  selector:
    app: tts
  ports:
  - name: http
    protocol: TCP
    port: 80
    targetPort: 12345
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: tts
  namespace: mumble
  labels:
    app: tts
spec:
  replicas: 3
  selector:
    matchLabels:
      app: tts
  template:
    metadata:
      labels:
        app: tts
      annotations:
        bump: '1'
    spec:
      terminationGracePeriodSeconds: 60
      imagePullSecrets:
      - name: regcred
      volumes:
      - name: devfuse
        hostPath:
          path: /dev/fuse
      - name: mntdatas3fs
        # NB: Doesn't set an explicit hostpath because:
        # error while creating mount source path '...': mkdir ...: file exists
        #emptyDir: {}
        # NB: *ACTUALLY*, the above error happened with emptyDir too. I don't know
        # what the problem is. Additionally, I had to introduce '-o nonempty' as 
        # described in the env vars section below.
        hostPath:
          path: /dev/fuse_data_mountpt
          type: DirectoryOrCreate
      containers:
      - name: s3fs
        securityContext:
          privileged: true
          allowPrivilegeEscalation: true
        # TODO: Find a pinned tag for this. `latest` is dangerous
        # This is ancient (2~3 years old): https://github.com/panubo/docker-s3fs
        # This is what it wraps, and it is very recent: https://github.com/s3fs-fuse/s3fs-fuse
        image: panubo/s3fs:latest
        # NB: This container spews logs, making Graphana hard to read. I can't figure
        # out how to filter out by sidecar, label, app, whatever, so I'm disabling these
        # logs outright. I do not anticipate a problem with s3fs that I'll need logs for.
        # If I change my mind, I can remove the override setting in the future, because
        # Docker has the correct entrypoint.
        command: ["/bin/sh"]
        args: ["-c", "echo 'Disabled s3fs logging in k8s deployment for Graphana' && ./entry.sh 2> /dev/null"]
        volumeMounts:
        - name: devfuse
          mountPath: /dev/fuse
        - name: mntdatas3fs
          mountPath: /data:shared
        env:
        - name: AWS_S3_URL
          value: "https://nyc3.digitaloceanspaces.com"
        - name: AWS_STORAGE_BUCKET_NAME
          value: "upload-models"
        - name: AWS_ACCESS_KEY_ID
          valueFrom:
            secretKeyRef:
              name: spaces-secrets
              key: aws_access_key_id
        - name: AWS_SECRET_ACCESS_KEY
          valueFrom:
            secretKeyRef:
              name: spaces-secrets
              key: aws_secret_access_key
        - name: AWS_S3_MOUNTPOINT
          value: "/data"
        - name: DEBUG
          value: "true"
          # Per this message,
          #     "s3fs: MOUNTPOINT directory /data is not empty. if you are sure this is safe, can use
          #      the 'nonempty' mount option"
          # To appease 'hostMount' volume, I think this will work:
        - name: S3FS_ARGS
          value: "-o nonempty"
      - name: tts
        # NB: Container builds are triggered by Github Actions
        #image: docker.pkg.github.com/echelon/voder/tts-service:374e1a477d90

        # The following image runs a non-Arpabet engine that can run an 
        # LSpeech model that sounds 100% amazing
        # image: docker.pkg.github.com/echelon/voder/tts-service:6b5c22567614

        # The following image runs a rudimentary Arbapet engine, but doesn't
        # handle puncutation and tokenization
        #image: docker.pkg.github.com/ml-applications/voder/tts-service:6e766720ca7d
        image: docker.pkg.github.com/ml-applications/voder/tts-service:b4dd56b65cb4
        volumeMounts:
        - name: mntdatas3fs
          mountPath: /data:shared
        env:
        - name: BIND_ADDRESS
          value: "0.0.0.0:12345"
        - name: ASSET_DIRECTORY
          value: "/data/frontend/build"
        - name: MODEL_CONFIG_FILE
          value: "/data/models/deployed_models.toml"
        command: ["./launch.sh"]
        args: [""]
        #command: ["sleep"]
        #args: ["300000"]
        ports:
        - containerPort: 12345
          protocol: TCP
        # If the readiness probe fails, the container is removed from the service.
        readinessProbe:
          httpGet:
            path: /readiness
            port: 12345
          # Check every two seconds.
          periodSeconds: 2
          # Warmup period before first check.
          initialDelaySeconds: 5
          # How long it takes for the probe to time out.
          timeoutSeconds: 1
          # Number of attempts before the pod is marked unready
          failureThreshold: 1
        # If the liveness probe fails, the container is subject to its restart policy
        # Since the container can crash on its own, we'll omit this.
        # livenessProbe:
        #   httpGet:
        #     path: /liveness
        #     port: 12345
        #   initialDelaySeconds: 20
        #   periodSeconds: 10
        #   timeoutSeconds: 3
        #   failureThreshold: 3
